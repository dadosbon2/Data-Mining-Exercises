{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZCgrH8tnTBLB"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLOTUMbuTBLB"
      },
      "source": [
        "NLP From Scratch: Classifying Names with a Character-Level RNN\n",
        "==============================================================\n",
        "\n",
        "**Author**: [Sean Robertson](https://github.com/spro)\n",
        "\n",
        "This tutorials is part of a three-part series:\n",
        "\n",
        "-   [NLP From Scratch: Classifying Names with a Character-Level\n",
        "    RNN](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)\n",
        "-   [NLP From Scratch: Generating Names with a Character-Level\n",
        "    RNN](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)\n",
        "-   [NLP From Scratch: Translation with a Sequence to Sequence Network\n",
        "    and\n",
        "    Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
        "\n",
        "We will be building and training a basic character-level Recurrent\n",
        "Neural Network (RNN) to classify words. This tutorial, along with two\n",
        "other Natural Language Processing (NLP) \\\"from scratch\\\" tutorials\n",
        "`/intermediate/char_rnn_generation_tutorial`{.interpreted-text\n",
        "role=\"doc\"} and\n",
        "`/intermediate/seq2seq_translation_tutorial`{.interpreted-text\n",
        "role=\"doc\"}, show how to preprocess data to model NLP. In particular,\n",
        "these tutorials show how preprocessing to model NLP works at a low\n",
        "level.\n",
        "\n",
        "A character-level RNN reads words as a series of characters -outputting\n",
        "a prediction and \\\"hidden state\\\" at each step, feeding its previous\n",
        "hidden state into each next step. We take the final prediction to be the\n",
        "output, i.e. which class the word belongs to.\n",
        "\n",
        "Specifically, we\\'ll train on a few thousand surnames from 18 languages\n",
        "of origin, and predict which language a name is from based on the\n",
        "spelling:\n",
        "\n",
        "``` {.sh}\n",
        "$ python predict.py Hinton\n",
        "(-0.47) Scottish\n",
        "(-1.52) English\n",
        "(-3.57) Irish\n",
        "\n",
        "$ python predict.py Schmidhuber\n",
        "(-0.19) German\n",
        "(-2.48) Czech\n",
        "(-2.68) Dutch\n",
        "```\n",
        "\n",
        "Recommended Preparation\n",
        "-----------------------\n",
        "\n",
        "Before starting this tutorial it is recommended that you have installed\n",
        "PyTorch, and have a basic understanding of Python programming language\n",
        "and Tensors:\n",
        "\n",
        "-   <https://pytorch.org/> For installation instructions\n",
        "-   `/beginner/deep_learning_60min_blitz`{.interpreted-text role=\"doc\"}\n",
        "    to get started with PyTorch in general and learn the basics of\n",
        "    Tensors\n",
        "-   `/beginner/pytorch_with_examples`{.interpreted-text role=\"doc\"} for\n",
        "    a wide and deep overview\n",
        "-   `/beginner/former_torchies_tutorial`{.interpreted-text role=\"doc\"}\n",
        "    if you are former Lua Torch user\n",
        "\n",
        "It would also be useful to know about RNNs and how they work:\n",
        "\n",
        "-   [The Unreasonable Effectiveness of Recurrent Neural\n",
        "    Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "    shows a bunch of real life examples\n",
        "-   [Understanding LSTM\n",
        "    Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "    is about LSTMs specifically but also informative about RNNs in\n",
        "    general\n",
        "\n",
        "Preparing the Data\n",
        "------------------\n",
        "\n",
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
        "\n",
        "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
        "\n",
        "<p>Download the data from<a href=\"https://download.pytorch.org/tutorial/data.zip\">here</a>and extract it to the current directory.</p>\n",
        "\n",
        "</div>\n",
        "\n",
        "Included in the `data/names` directory are 18 text files named as\n",
        "`[Language].txt`. Each file contains a bunch of names, one name per\n",
        "line, mostly romanized (but we still need to convert from Unicode to\n",
        "ASCII).\n",
        "\n",
        "We\\'ll end up with a dictionary of lists of names per language,\n",
        "`{language: [names ...]}`. The generic variables \\\"category\\\" and\n",
        "\\\"line\\\" (for language and name in our case) are used for later\n",
        "extensibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-Pm2u124TBLC",
        "outputId": "e04b9b03-e13a-4b0e-dcf1-1b93eb4a7b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data/names/Spanish.txt', 'data/names/Scottish.txt', 'data/names/Chinese.txt', 'data/names/English.txt', 'data/names/Vietnamese.txt', 'data/names/Russian.txt', 'data/names/French.txt', 'data/names/German.txt', 'data/names/Portuguese.txt', 'data/names/Irish.txt', 'data/names/Dutch.txt', 'data/names/Italian.txt', 'data/names/Czech.txt', 'data/names/Polish.txt', 'data/names/Japanese.txt', 'data/names/Greek.txt', 'data/names/Arabic.txt', 'data/names/Korean.txt']\n",
            "Slusarski\n",
            "18\n"
          ]
        }
      ],
      "source": [
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "#open function from the io module, making reading and writing files simpler\n",
        "#glob allow us to find files with the extension .txt in the \"data\" directory/folder\n",
        "#os  is a  module that interact with the operating system: it navigates directories, check the existence of files, can edit file paths\n",
        "\n",
        "def findFiles(path): return glob.glob(path)\n",
        "#this function returns a list of filepaths that match the pattern\n",
        "print(findFiles('data/names/*.txt'))\n",
        "#This prints the list of filepaths\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "#two modules used for string manipulation and unicode transformation of characters\n",
        "\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {} #list of names per language\n",
        "all_categories = [] #list of languages handled by the algorithm\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename) #ädd language to the list\n",
        "    category_lines[category] = lines #add names to the langauges list, technically called dictionary\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "print(n_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d10uFS4LTBLD"
      },
      "source": [
        "Now we have `category_lines`, a dictionary mapping each category\n",
        "(language) to a list of lines (names). We also kept track of\n",
        "`all_categories` (just a list of languages) and `n_categories` for later\n",
        "reference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "04bs5QPTTBLD",
        "outputId": "3e760291-66e4-427e-c25a-8b7e2ca8757b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
          ]
        }
      ],
      "source": [
        "print(category_lines['Italian'][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S14QhV21TBLD"
      },
      "source": [
        "Turning Names into Tensors\n",
        "==========================\n",
        "\n",
        "Now that we have all the names organized, we need to turn them into\n",
        "Tensors to make any use of them.\n",
        "\n",
        "To represent a single letter, we use a \\\"one-hot vector\\\" of size\n",
        "`<1 x n_letters>`. A one-hot vector is filled with 0s except for a 1 at\n",
        "index of the current letter, e.g. `\"b\" = <0 1 0 0 0 ...>`.\n",
        "\n",
        "To make a word we join a bunch of those into a 2D matrix\n",
        "`<line_length x 1 x n_letters>`.\n",
        "\n",
        "That extra 1 dimension is because PyTorch assumes everything is in\n",
        "batches - we\\'re just using a batch size of 1 here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7U9yXO5eTBLE",
        "outputId": "5be2a6be-551d-4773-f57e-ee91dcf4711d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]])\n",
            "torch.Size([5, 1, 57])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "#module that let us do operations using Tensors\n",
        "\n",
        "# Find letter index from all_letters, e.g. \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter) #it gives back the position of the letter\n",
        "\n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters) #Initialize a tensor of shape 1, n_letters\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters) # Initialize a zero tensor for the entire\n",
        "    for li, letter in enumerate(line): #Loop through each letter in line\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print(letterToTensor('J'))\n",
        "\n",
        "print(lineToTensor('Jones').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVvr1P2hTBLE"
      },
      "source": [
        "Creating the Network\n",
        "====================\n",
        "\n",
        "Before autograd, creating a recurrent neural network in Torch involved\n",
        "cloning the parameters of a layer over several timesteps. The layers\n",
        "held hidden state and gradients which are now entirely handled by the\n",
        "graph itself. This means you can implement a RNN in a very \\\"pure\\\" way,\n",
        "as regular feed-forward layers.\n",
        "\n",
        "This RNN module implements a \\\"vanilla RNN\\\" an is just 3 linear layers\n",
        "which operate on an input and hidden state, with a `LogSoftmax` layer\n",
        "after the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Fyed6ectTBLE"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNN(nn.Module):   #Here the RNN class is defined\n",
        "    def __init__(self, input_size, hidden_size, output_size): #base class (nn.Module) constructor\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size #Here it is possible to set the size of hidden layers\n",
        "\n",
        "        self.i2h = nn.Linear(input_size, hidden_size) # Maps inputs to hidden state\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)# recurrent conectionces between hidden states(here comes the idea of neuronal network)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)# maps hidden state to output\n",
        "        self.softmax = nn.LogSoftmax(dim=1)# activation function is log-softmax for the output for classification probabilities\n",
        "\n",
        "    def forward(self, input, hidden): #Forward pass\n",
        "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
        "        output = self.h2o(hidden)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden # returns output and new hidden state\n",
        "\n",
        "    def initHidden(self): #Initialize the hidden state to zero\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFFJrFaQTBLF"
      },
      "source": [
        "To run a step of this network we need to pass an input (in our case, the\n",
        "Tensor for the current letter) and a previous hidden state (which we\n",
        "initialize as zeros at first). We\\'ll get back the output (probability\n",
        "of each language) and a next hidden state (which we keep for the next\n",
        "step).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tgzf1frxTBLF"
      },
      "outputs": [],
      "source": [
        "input = letterToTensor('A')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input, hidden)\n",
        "\n",
        "#This is the representation of a single step in the RNN for letter A, for the rest\n",
        "#of the name, this process would be repeated for each letter, so next_hidden would be the next letter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCSsL1waTBLF"
      },
      "source": [
        "For the sake of efficiency we don\\'t want to be creating a new Tensor\n",
        "for every step, so we will use `lineToTensor` instead of\n",
        "`letterToTensor` and use slices. This could be further optimized by\n",
        "precomputing batches of Tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GrOyodzITBLF",
        "outputId": "f03aef38-9702-4911-8a71-0ccde765972e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.7812, -2.8908, -2.9109, -2.8170, -2.8450, -2.8424, -3.0461, -2.8599,\n",
            "         -2.8624, -2.9785, -2.9244, -2.9477, -2.9376, -2.8345, -2.8342, -2.9530,\n",
            "         -2.9220, -2.8756]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input = lineToTensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlCNBR8JTBLF"
      },
      "source": [
        "As you can see the output is a `<1 x n_categories>` Tensor, where every\n",
        "item is the likelihood of that category (higher is more likely).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk97abwaTBLF"
      },
      "source": [
        "Training\n",
        "========\n",
        "\n",
        "Preparing for Training\n",
        "----------------------\n",
        "\n",
        "Before going into training we should make a few helper functions. The\n",
        "first is to interpret the output of the network, which we know to be a\n",
        "likelihood of each category. We can use `Tensor.topk` to get the index\n",
        "of the greatest value:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KxMM5qwuTBLG",
        "outputId": "be6b4796-6953-43bc-963e-dac859474e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Spanish', 0)\n"
          ]
        }
      ],
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(categoryFromOutput(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCmNydycTBLG"
      },
      "source": [
        "We will also want a quick way to get a training example (a name and its\n",
        "language):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DX2FBi_eTBLG",
        "outputId": "94b217d8-eac2-473d-a3bc-28836844f27f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category = Chinese / line = Zhang\n",
            "category = Scottish / line = Macdonald\n",
            "category = French / line = Girard\n",
            "category = Czech / line = Osladil\n",
            "category = Italian / line = Falco\n",
            "category = Irish / line = Donoghue\n",
            "category = French / line = Renaud\n",
            "category = Russian / line = Ladyjensky\n",
            "category = French / line = Paget\n",
            "category = Dutch / line = Reynder\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample():\n",
        "    category = randomChoice(all_categories)\n",
        "    line = randomChoice(category_lines[category])\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = lineToTensor(line)\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    print('category =', category, '/ line =', line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6deDYiuTBLG"
      },
      "source": [
        "Training the Network\n",
        "====================\n",
        "\n",
        "Now all it takes to train this network is show it a bunch of examples,\n",
        "have it make guesses, and tell it if it\\'s wrong.\n",
        "\n",
        "For the loss function `nn.NLLLoss` is appropriate, since the last layer\n",
        "of the RNN is `nn.LogSoftmax`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mQ09vVazTBLG"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIMwEqMcTBLG"
      },
      "source": [
        "Each loop of training will:\n",
        "\n",
        "-   Create input and target tensors\n",
        "-   Create a zeroed initial hidden state\n",
        "-   Read each letter in and\n",
        "    -   Keep hidden state for next letter\n",
        "-   Compare final output to target\n",
        "-   Back-propagate\n",
        "-   Return the output and loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "z50_RUV6TBLG"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
        "\n",
        "def train(category_tensor, line_tensor):\n",
        "  #Initialze the hidden state for the RNN\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "  # the gradients are brought back to zero from the previous backward pass\n",
        "    rnn.zero_grad()\n",
        "\n",
        "  #Loop through each character in the input line_tensor\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor) # calculates the loss by comparing predicting output vs true categories\n",
        "\n",
        "    loss.backward() #backpropagation\n",
        "\n",
        "    # Add parameters' gradients to their values, multiplied by learning rate\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymg2aCJfTBLG"
      },
      "source": [
        "Now we just have to run that with a bunch of examples. Since the `train`\n",
        "function returns both the output and loss we can print its guesses and\n",
        "also keep track of loss for plotting. Since there are 1000s of examples\n",
        "we print only every `print_every` examples, and take an average of the\n",
        "loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B-9iu_ARTBLH",
        "outputId": "5a4be7bb-63fb-4bcd-9c57-47737f1aeac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000 5% (0m 8s) 2.6890 Tyrrell / Irish ✗ (English)\n",
            "10000 10% (0m 15s) 3.2845 Jamussa / Polish ✗ (Greek)\n",
            "15000 15% (0m 24s) 0.9179 Luo / Chinese ✓\n",
            "20000 20% (0m 31s) 1.2245 Srour / Arabic ✓\n",
            "25000 25% (0m 40s) 2.9902 Segal / Czech ✗ (French)\n",
            "30000 30% (0m 48s) 0.6437 Siu / Chinese ✓\n",
            "35000 35% (0m 56s) 3.2055 Azzara / Spanish ✗ (Italian)\n",
            "40000 40% (1m 4s) 1.2043 Sutherland / Scottish ✓\n",
            "45000 45% (1m 13s) 0.1306 Bertsimas / Greek ✓\n",
            "50000 50% (1m 20s) 1.1505 Charpentier / French ✓\n",
            "55000 55% (1m 29s) 0.7205 Kan / Chinese ✓\n",
            "60000 60% (1m 37s) 1.4466 Pennington / Scottish ✗ (English)\n",
            "65000 65% (1m 44s) 0.3168 Liu / Chinese ✓\n",
            "70000 70% (1m 53s) 0.4608 Artizov / Russian ✓\n",
            "75000 75% (2m 1s) 0.0198 Koizumi / Japanese ✓\n",
            "80000 80% (2m 8s) 3.1722 Ashia / Arabic ✗ (Japanese)\n",
            "85000 85% (2m 17s) 1.8680 Manson / Scottish ✗ (English)\n",
            "90000 90% (2m 25s) 1.9529 Mayer / Arabic ✗ (German)\n",
            "95000 95% (2m 33s) 0.1195 Minatoya / Japanese ✓\n",
            "100000 100% (2m 42s) 0.0010 Agelakos / Greek ✓\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "\n",
        "\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print ``iter`` number, loss, name and guess\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhCBgMeOTBLH"
      },
      "source": [
        "Plotting the Results\n",
        "====================\n",
        "\n",
        "Plotting the historical loss from `all_losses` shows the network\n",
        "learning:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9QaBmFbeTBLH",
        "outputId": "4e4a02cc-749c-4a8d-ad39-5320dcb0c664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc8b693d150>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)\n",
        "#As we can see the plot as trend to decrease over time, this is due the model perfomance improving\n",
        "#meaning less mistakes are  being done/Algorithm is learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AV6JqONTBLH"
      },
      "source": [
        "Evaluating the Results\n",
        "======================\n",
        "\n",
        "To see how well the network performs on different categories, we will\n",
        "create a confusion matrix, indicating for every actual language (rows)\n",
        "which language the network guesses (columns). To calculate the confusion\n",
        "matrix a bunch of samples are run through the network with `evaluate()`,\n",
        "which is the same as `train()` minus the backprop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VvXSwc9KTBLH",
        "outputId": "8d69d0d0-40ae-4819-d8c5-b609fc780025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-1c4b9dd31c42>:33: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels([''] + all_categories, rotation=90)\n",
            "<ipython-input-20-1c4b9dd31c42>:34: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels([''] + all_categories)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Keep track of correct guesses in a confusion matrix\n",
        "confusion = torch.zeros(n_categories, n_categories)\n",
        "n_confusion = 10000\n",
        "\n",
        "# Just return an output given a line\n",
        "def evaluate(line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Go through a bunch of examples and record which are correctly guessed\n",
        "for i in range(n_confusion):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output = evaluate(line_tensor)\n",
        "    guess, guess_i = categoryFromOutput(output)\n",
        "    category_i = all_categories.index(category)\n",
        "    confusion[category_i][guess_i] += 1\n",
        "\n",
        "# Normalize by dividing every row by its sum\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()\n",
        "\n",
        "# Set up plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion.numpy())\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# Set up axes\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "\n",
        "# Force label at every tick\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "# sphinx_gallery_thumbnail_number = 2\n",
        "plt.show()\n",
        "\n",
        "############\n",
        "\n",
        "#The confusion matrix shows how well did the model predict that a name belonged to certein category\n",
        "#It seems to work the best with Vietnamese and Arab names. While it seems to struggle only with English.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1VypY2qTBLH"
      },
      "source": [
        "You can pick out bright spots off the main axis that show which\n",
        "languages it guesses incorrectly, e.g. Chinese for Korean, and Spanish\n",
        "for Italian. It seems to do very well with Greek, and very poorly with\n",
        "English (perhaps because of overlap with other languages).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABNlUno5TBLH"
      },
      "source": [
        "Running on User Input\n",
        "=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4vnEINABTBLH",
        "outputId": "88a20da6-cf3e-4c3f-b1c9-9e47bcca99c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Dovesky\n",
            "(-0.66) Russian\n",
            "(-1.01) Czech\n",
            "(-2.50) English\n",
            "\n",
            "> Jackson\n",
            "(-0.05) Scottish\n",
            "(-3.32) English\n",
            "(-5.15) Russian\n",
            "\n",
            "> Satoshi\n",
            "(-0.51) Japanese\n",
            "(-1.97) Italian\n",
            "(-2.41) Czech\n",
            "\n",
            "> Rivera\n",
            "(-0.17) Spanish\n",
            "(-2.05) Italian\n",
            "(-4.57) Dutch\n",
            "\n",
            "> Mirzoodilov\n",
            "(-0.30) Russian\n",
            "(-1.56) Polish\n",
            "(-3.29) Czech\n",
            "\n",
            "> Noßol\n",
            "(-0.88) Spanish\n",
            "(-1.10) Polish\n",
            "(-2.38) Czech\n",
            "\n",
            "> Jägger\n",
            "(-1.18) German\n",
            "(-1.28) Czech\n",
            "(-1.48) English\n"
          ]
        }
      ],
      "source": [
        "def predict(input_line, n_predictions=3):\n",
        "    print('\\n> %s' % input_line)\n",
        "    with torch.no_grad():\n",
        "        output = evaluate(lineToTensor(input_line))\n",
        "\n",
        "        # Get top N categories\n",
        "        topv, topi = output.topk(n_predictions, 1, True)\n",
        "        predictions = []\n",
        "\n",
        "        for i in range(n_predictions):\n",
        "            value = topv[0][i].item()\n",
        "            category_index = topi[0][i].item()\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "            predictions.append([value, all_categories[category_index]])\n",
        "\n",
        "predict('Dovesky')\n",
        "predict('Jackson')\n",
        "predict('Satoshi')\n",
        "predict('Rivera')\n",
        "predict('Mirzoodilov')\n",
        "predict('Noßol')\n",
        "predict('Jägger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esypgpa1TBLH"
      },
      "source": [
        "The final versions of the scripts [in the Practical PyTorch\n",
        "repo](https://github.com/spro/practical-pytorch/tree/master/char-rnn-classification)\n",
        "split the above code into a few files:\n",
        "\n",
        "-   `data.py` (loads files)\n",
        "-   `model.py` (defines the RNN)\n",
        "-   `train.py` (runs training)\n",
        "-   `predict.py` (runs `predict()` with command line arguments)\n",
        "-   `server.py` (serve prediction as a JSON API with `bottle.py`)\n",
        "\n",
        "Run `train.py` to train and save the network.\n",
        "\n",
        "Run `predict.py` with a name to view predictions:\n",
        "\n",
        "``` {.sh}\n",
        "$ python predict.py Hazaki\n",
        "(-0.42) Japanese\n",
        "(-1.39) Polish\n",
        "(-3.51) Czech\n",
        "```\n",
        "\n",
        "Run `server.py` and visit <http://localhost:5533/Yourname> to get JSON\n",
        "output of predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2o0vo4RTBLI"
      },
      "source": [
        "Exercises\n",
        "=========\n",
        "- 7.1 a\\) Comments to the code and plots where done in code using #.\n",
        "\n",
        "- b\\)**Pros:**  A RNN for characters from the  seems to be a great approach for name classification. After all names of diferent regions tend to follow a similar gramatic and orgin, which must leave some hidden patterns.\n",
        "\n",
        "  Thanks to the transformation of the names into ASCII code, the each character could be differentiated from each other.\n",
        "\n",
        "  Using backpropagation in the training loop, the model is able to learn, allowing the algorithm to catch the hidden patterns critical for the name classification. This improvement is visualized by monitoring the output of the loss function over time.\n",
        "\n",
        "- **Contras:**On the other hand the transformation of to ASCII, doesnt collect special symbols which could hint further the classification of the name, losing some data by simplying. And, while this was done for short data sets, in the future it might need enhancement layers or regularization techniques if larges data sets are used. It also lacks of memory during the sequential processing (meachinism to decide when to remember or forgent certain hidden states)\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "\n",
        "-   Try with a different dataset of line -\\> category, for example:\n",
        "    -   Any word -\\> language\n",
        "    -   First name -\\> gender\n",
        "    -   Character name -\\> writer\n",
        "    -   Page title -\\> blog or subreddit\n",
        "-   Get better results with a bigger and/or better shaped network\n",
        "    -   Add more linear layers\n",
        "    -   Try the `nn.LSTM` and `nn.GRU` layers\n",
        "    -   Combine multiple of these RNNs as a higher level network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.2 a\\)**"
      ],
      "metadata": {
        "id": "aex_khiN6NbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the dictionary \"category_lines\" into X (names) and y (categories)\n",
        "X = []  # List of names (inputs)\n",
        "y = []  # List of categories (labels)\n",
        "\n",
        "for category, names in category_lines.items():\n",
        "    X.extend(names)  # Add all names to X\n",
        "    y.extend([category] * len(names))  # Add the corresponding category to y\n",
        "\n",
        "print(f\"Number of samples: {len(X)}\")\n",
        "print(f\"Examples of X: {X[:5]}\")  # After the 5 names\n",
        "print(f\"Examples of y: {y[:5]}\")  # Corresponding categories\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2QGkc0WGJzy",
        "outputId": "1bdb3b02-123d-4a2d-b8a4-319f9f67b33c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 20074\n",
            "Examples of X: ['Abana', 'Abano', 'Abarca', 'Abaroa', 'Abascal']\n",
            "Examples of y: ['Spanish', 'Spanish', 'Spanish', 'Spanish', 'Spanish']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3OzSaj-Gtwd",
        "outputId": "974b3d79-23db-4f3c-905a-30a7b115ef6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 16059\n",
            "Testing samples: 4015\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16059, 4015, 16059, 4015)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def randomTrainingExample():\n",
        "    import random\n",
        "    i = random.randint(0, len(X_train) - 1)\n",
        "    line = X_train[i]\n",
        "    category = y_train[i]\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = lineToTensor(line)\n",
        "    return category, line, category_tensor, line_tensor"
      ],
      "metadata": {
        "id": "Yu0CwC5RONGe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "# Function to evaluate accuracy on test set\n",
        "def evaluate():\n",
        "    rnn.eval()\n",
        "    correct = 0\n",
        "    total = len(X_test)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total):\n",
        "            line = X_test[i]\n",
        "            category = y_test[i]\n",
        "            category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "            line_tensor = lineToTensor(line)\n",
        "\n",
        "            hidden = rnn.initHidden()\n",
        "            for j in range(line_tensor.size()[0]):\n",
        "                output, hidden = rnn(line_tensor[j], hidden)\n",
        "\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            if guess == category:\n",
        "                correct += 1\n",
        "    return correct / total\n",
        "\n",
        "# Time helper function\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# Set parameters\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Training function\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "# Start training\n",
        "start = time.time()\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print progress\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        test_accuracy = evaluate()\n",
        "        print('%d %d%% (%s) Loss: %.4f | Test Accuracy: %.2f%% | %s / %s %s' %\n",
        "              (iter, iter / n_iters * 100, timeSince(start), loss, test_accuracy * 100, line, guess, correct))\n",
        "\n",
        "    # Plot losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0\n",
        "\n",
        "\n",
        "    #It seems that the model get an accuracy average of ~77% after the firs 5 runs\n",
        "    #The training data was splited into 20 percent training and 80 percent test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xewY8YAMPhmr",
        "outputId": "22bd46a8-4ae2-4836-d4e3-7b6c636ba59f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000 5% (0m 11s) Loss: 0.0034 | Test Accuracy: 74.72% | Zinov / Russian ✓\n",
            "10000 10% (0m 23s) Loss: 0.0080 | Test Accuracy: 75.97% | BeknazarYuzbashev / Russian ✓\n",
            "15000 15% (0m 34s) Loss: 0.8980 | Test Accuracy: 75.04% | Tassioglou / Greek ✓\n",
            "20000 20% (0m 46s) Loss: 1.1988 | Test Accuracy: 76.39% | Verney / Russian ✗ (English)\n",
            "25000 25% (0m 57s) Loss: 0.9342 | Test Accuracy: 75.37% | Baumgarten / Russian ✓\n",
            "30000 30% (1m 9s) Loss: 0.0280 | Test Accuracy: 75.74% | Lutov / Russian ✓\n",
            "35000 35% (1m 20s) Loss: 3.8292 | Test Accuracy: 75.77% | Silva / Polish ✗ (Portuguese)\n",
            "40000 40% (1m 31s) Loss: 1.2440 | Test Accuracy: 75.74% | Horn / English ✗ (German)\n",
            "45000 45% (1m 43s) Loss: 0.3549 | Test Accuracy: 76.61% | Bernard / English ✓\n",
            "50000 50% (1m 55s) Loss: 3.6235 | Test Accuracy: 74.65% | Tykal / Russian ✗ (Czech)\n",
            "55000 55% (2m 7s) Loss: 0.0022 | Test Accuracy: 77.38% | Anisikhin / Russian ✓\n",
            "60000 60% (2m 18s) Loss: 0.2177 | Test Accuracy: 76.96% | Avdiyants / Russian ✓\n",
            "65000 65% (2m 30s) Loss: 0.1574 | Test Accuracy: 76.41% | Junda / Russian ✓\n",
            "70000 70% (2m 42s) Loss: 0.0066 | Test Accuracy: 76.46% | Maroun / Arabic ✓\n",
            "75000 75% (2m 53s) Loss: 0.0281 | Test Accuracy: 71.53% | Paidoverov / Russian ✓\n",
            "80000 80% (3m 5s) Loss: 0.0022 | Test Accuracy: 76.69% | Yanenko / Russian ✓\n",
            "85000 85% (3m 18s) Loss: 0.0015 | Test Accuracy: 77.78% | Yujenko / Russian ✓\n",
            "90000 90% (3m 29s) Loss: 0.0002 | Test Accuracy: 75.37% | Jakubovsky / Russian ✓\n",
            "95000 95% (3m 40s) Loss: 0.0747 | Test Accuracy: 78.11% | Assaf / Arabic ✓\n",
            "100000 100% (3m 51s) Loss: 0.0084 | Test Accuracy: 77.06% | Mansour / Arabic ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b\\)**"
      ],
      "metadata": {
        "id": "pLQi03S6MzpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import math\n",
        "\n",
        "# Function to evaluate accuracy on test set\n",
        "def evaluate():\n",
        "    rnn.eval()\n",
        "    correct = 0\n",
        "    total = len(X_test)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total):\n",
        "            line = X_test[i]\n",
        "            category = y_test[i]\n",
        "            category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long).to(device)\n",
        "            line_tensor = lineToTensor(line).to(device)  # Move to device\n",
        "\n",
        "            hidden = rnn.initHidden().to(device)  # Move hidden state to device\n",
        "            for j in range(line_tensor.size()[0]):\n",
        "                output, hidden = rnn(line_tensor[j], hidden)\n",
        "\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            if guess == category:\n",
        "                correct += 1\n",
        "    return correct / total\n",
        "\n",
        "# Time helper function\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# Set parameters\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Training function\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden().to(device)  # Move hidden state to device\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {device}\")\n",
        "\n",
        "# Move model to device (GPU if available)\n",
        "rnn.to(device)\n",
        "\n",
        "# Start timer\n",
        "start = time.time()\n",
        "\n",
        "# Training loop on GPU\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    category_tensor = category_tensor.to(device)  # Move category tensor to device\n",
        "    line_tensor = line_tensor.to(device)  # Move line tensor to device\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print progress\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        test_accuracy = evaluate()\n",
        "        print(f'{iter} {iter / n_iters * 100:.2f}% ({timeSince(start)}) Loss: {loss:.4f} | Test Accuracy: {test_accuracy * 100:.2f}% | {line} / {guess} {correct}')\n",
        "\n",
        "    # Plot losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0\n",
        "\n",
        "# Total training time on GPU\n",
        "total_time_gpu = time.time() - start\n",
        "print(f\"Training time on GPU: {total_time_gpu:.2f} seconds\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1opzXab2ePAt",
        "outputId": "18458bd9-1d35-4537-84fe-116d842812b5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda\n",
            "5000 5.00% (0m 22s) Loss: 0.0019 | Test Accuracy: 77.24% | Alshevsky / Russian ✓\n",
            "10000 10.00% (0m 45s) Loss: 0.0511 | Test Accuracy: 76.24% | Ashford / English ✓\n",
            "15000 15.00% (1m 11s) Loss: 0.0382 | Test Accuracy: 76.49% | Ellard / English ✓\n",
            "20000 20.00% (1m 33s) Loss: 0.2341 | Test Accuracy: 76.64% | Santo / Japanese ✓\n",
            "25000 25.00% (1m 55s) Loss: 0.5780 | Test Accuracy: 77.19% | Geiszler / German ✓\n",
            "30000 30.00% (2m 18s) Loss: 0.1014 | Test Accuracy: 78.53% | Mukin / Russian ✓\n",
            "35000 35.00% (2m 41s) Loss: 0.0005 | Test Accuracy: 77.38% | Tujikov / Russian ✓\n",
            "40000 40.00% (3m 4s) Loss: 0.0095 | Test Accuracy: 76.59% | Iijima / Japanese ✓\n",
            "45000 45.00% (3m 26s) Loss: 0.5007 | Test Accuracy: 78.43% | Fisun / Russian ✓\n",
            "50000 50.00% (3m 49s) Loss: 0.0250 | Test Accuracy: 77.29% | Woollard / English ✓\n",
            "55000 55.00% (4m 11s) Loss: 0.0019 | Test Accuracy: 75.62% | Mikhail / Arabic ✓\n",
            "60000 60.00% (4m 34s) Loss: 0.0001 | Test Accuracy: 76.89% | Jakunkin / Russian ✓\n",
            "65000 65.00% (4m 57s) Loss: 0.1890 | Test Accuracy: 75.54% | Trapani / Italian ✓\n",
            "70000 70.00% (5m 19s) Loss: 2.5450 | Test Accuracy: 77.53% | Michudo / Japanese ✗ (Russian)\n",
            "75000 75.00% (5m 42s) Loss: 0.0838 | Test Accuracy: 77.83% | Kaminaga / Japanese ✓\n",
            "80000 80.00% (6m 5s) Loss: 3.2515 | Test Accuracy: 77.73% | Karl / Czech ✗ (German)\n",
            "85000 85.00% (6m 28s) Loss: 0.0859 | Test Accuracy: 78.48% | Yau / Chinese ✓\n",
            "90000 90.00% (6m 50s) Loss: 0.0059 | Test Accuracy: 78.48% | Batchev / Russian ✓\n",
            "95000 95.00% (7m 12s) Loss: 5.0237 | Test Accuracy: 76.46% | Venne / English ✗ (Dutch)\n",
            "100000 100.00% (7m 35s) Loss: 0.0935 | Test Accuracy: 78.75% | Millar / English ✓\n",
            "Training time on GPU: 455.19 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import math\n",
        "\n",
        "# Function to evaluate accuracy on test set\n",
        "def evaluate():\n",
        "    rnn.eval()\n",
        "    correct = 0\n",
        "    total = len(X_test)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total):\n",
        "            line = X_test[i]\n",
        "            category = y_test[i]\n",
        "            category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long).to(device)\n",
        "            line_tensor = lineToTensor(line).to(device)  # Move to device\n",
        "\n",
        "            hidden = rnn.initHidden().to(device)  # Move hidden state to device\n",
        "            for j in range(line_tensor.size()[0]):\n",
        "                output, hidden = rnn(line_tensor[j], hidden)\n",
        "\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            if guess == category:\n",
        "                correct += 1\n",
        "    return correct / total\n",
        "\n",
        "# Time helper function\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# Set parameters\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Training function\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden().to(device)  # Move hidden state to device\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "# Use CPU\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"Training on {device}\")\n",
        "\n",
        "# Move model to CPU\n",
        "rnn.to(device)\n",
        "\n",
        "# Start timer\n",
        "start = time.time()\n",
        "\n",
        "# Training loop on CPU\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    category_tensor = category_tensor.to(device)  # Move category tensor to device\n",
        "    line_tensor = line_tensor.to(device)  # Move line tensor to device\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print progress\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        test_accuracy = evaluate()\n",
        "        print(f'{iter} {iter / n_iters * 100:.2f}% ({timeSince(start)}) Loss: {loss:.4f} | Test Accuracy: {test_accuracy * 100:.2f}% | {line} / {guess} {correct}')\n",
        "\n",
        "    # Plot losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0\n",
        "\n",
        "# Total training time on CPU\n",
        "total_time_cpu = time.time() - start\n",
        "print(f\"Training time on CPU: {total_time_cpu:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf-G1wPTM_pQ",
        "outputId": "453981ba-b641-48cc-d214-96ac02c96eb3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "5000 5.00% (0m 12s) Loss: 3.9479 | Test Accuracy: 76.36% | De leon / English ✗ (Spanish)\n",
            "10000 10.00% (0m 24s) Loss: 3.2409 | Test Accuracy: 77.01% | Jippensha / Russian ✗ (Japanese)\n",
            "15000 15.00% (0m 36s) Loss: 3.8297 | Test Accuracy: 76.79% | Petersen / German ✗ (Czech)\n",
            "20000 20.00% (0m 48s) Loss: 0.0004 | Test Accuracy: 78.06% | Halatov / Russian ✓\n",
            "25000 25.00% (1m 0s) Loss: 0.0172 | Test Accuracy: 77.21% | Kalitvin / Russian ✓\n",
            "30000 30.00% (1m 14s) Loss: 1.1773 | Test Accuracy: 76.79% | Harker / German ✗ (English)\n",
            "35000 35.00% (1m 26s) Loss: 0.0004 | Test Accuracy: 76.86% | Durmanov / Russian ✓\n",
            "40000 40.00% (1m 38s) Loss: 0.0064 | Test Accuracy: 75.94% | O'Neal / Irish ✓\n",
            "45000 45.00% (1m 50s) Loss: 0.0133 | Test Accuracy: 76.76% | Ustvolsky / Russian ✓\n",
            "50000 50.00% (2m 2s) Loss: 0.5215 | Test Accuracy: 77.11% | Nifterick / Dutch ✓\n",
            "55000 55.00% (2m 13s) Loss: 2.1146 | Test Accuracy: 77.16% | Wright / English ✗ (Scottish)\n",
            "60000 60.00% (2m 25s) Loss: 0.0369 | Test Accuracy: 76.36% | Jindra / Czech ✓\n",
            "65000 65.00% (2m 37s) Loss: 0.0024 | Test Accuracy: 76.44% | Badelin / Russian ✓\n",
            "70000 70.00% (2m 49s) Loss: 0.1020 | Test Accuracy: 74.57% | Mlodik / Russian ✓\n",
            "75000 75.00% (3m 1s) Loss: 0.1788 | Test Accuracy: 77.16% | Dzhugashvili / Russian ✓\n",
            "80000 80.00% (3m 13s) Loss: 0.0024 | Test Accuracy: 75.72% | Yujilin / Russian ✓\n",
            "85000 85.00% (3m 25s) Loss: 0.0415 | Test Accuracy: 76.41% | Kennard / English ✓\n",
            "90000 90.00% (3m 37s) Loss: 0.2355 | Test Accuracy: 76.64% | Waclauska / Czech ✓\n",
            "95000 95.00% (3m 50s) Loss: 0.1085 | Test Accuracy: 77.29% | Portnenko / Russian ✓\n",
            "100000 100.00% (4m 2s) Loss: 0.0148 | Test Accuracy: 77.29% | O'Hanlon / Irish ✓\n",
            "Training time on CPU: 242.31 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Surprisingly the CPU had better runtime with 242.31 seconds for the training compared to 455.19 seconds it needed while using the GPU (T4 from Google Colab)"
      ],
      "metadata": {
        "id": "yMa8vHK5obgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c\\)**"
      ],
      "metadata": {
        "id": "Aqv-sVSQlwx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "n_hidden = 512  # Fourtimes of 128\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Define function to train and evaluate the model\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "# Function to evaluate accuracy on test set\n",
        "def evaluate():\n",
        "    rnn.eval()\n",
        "    correct = 0\n",
        "    total = len(X_test)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total):\n",
        "            line = X_test[i]\n",
        "            category = y_test[i]\n",
        "            category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "            line_tensor = lineToTensor(line)\n",
        "\n",
        "            hidden = rnn.initHidden()\n",
        "            for j in range(line_tensor.size()[0]):\n",
        "                output, hidden = rnn(line_tensor[j], hidden)\n",
        "\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            if guess == category:\n",
        "                correct += 1\n",
        "    return correct / total\n",
        "\n",
        "# Time helper function\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# Start training with the defined hidden size\n",
        "start = time.time()\n",
        "\n",
        "# Initialize RNN with the new hidden size\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print progress\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        test_accuracy = evaluate()\n",
        "        print(f'{iter} {iter / n_iters * 100:.2f}% ({timeSince(start)}) Loss: {loss:.4f} | Test Accuracy: {test_accuracy * 100:.2f}% | {line} / {guess} {correct}')\n",
        "\n",
        "    # Plot losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0\n",
        "\n",
        "# Total training time\n",
        "total_time = time.time() - start\n",
        "print(f\"Training time with {n_hidden} hidden units: {total_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLc_6liZrrj8",
        "outputId": "64d681a0-25e8-4a25-cb93-f5fa998f9673"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000 5.00% (0m 25s) Loss: 0.6896 | Test Accuracy: 65.33% | Ferris / English ✓\n",
            "10000 10.00% (0m 50s) Loss: 2.8409 | Test Accuracy: 61.89% | Selmone / English ✗ (Italian)\n",
            "15000 15.00% (1m 16s) Loss: 0.8208 | Test Accuracy: 64.81% | Tolley / English ✓\n",
            "20000 20.00% (1m 41s) Loss: 0.0007 | Test Accuracy: 70.54% | Nesmeyanov / Russian ✓\n",
            "25000 25.00% (2m 8s) Loss: 0.1871 | Test Accuracy: 69.86% | Attia / Arabic ✓\n",
            "30000 30.00% (2m 36s) Loss: 0.0057 | Test Accuracy: 72.40% | Valtchikovsky / Russian ✓\n",
            "35000 35.00% (3m 5s) Loss: 0.6716 | Test Accuracy: 71.96% | Liddell / English ✓\n",
            "40000 40.00% (3m 34s) Loss: 0.8589 | Test Accuracy: 73.05% | Parma / Italian ✓\n",
            "45000 45.00% (4m 3s) Loss: 1.9204 | Test Accuracy: 65.01% | Froman / English ✗ (Russian)\n",
            "50000 50.00% (4m 31s) Loss: 3.3679 | Test Accuracy: 70.29% | Tamboia / Japanese ✗ (Italian)\n",
            "55000 55.00% (5m 6s) Loss: 0.7860 | Test Accuracy: 73.57% | Drechsler / German ✓\n",
            "60000 60.00% (5m 33s) Loss: 0.4241 | Test Accuracy: 73.10% | Bologna / Italian ✓\n",
            "65000 65.00% (5m 59s) Loss: 4.4593 | Test Accuracy: 70.44% | Matsushina / Russian ✗ (Japanese)\n",
            "70000 70.00% (6m 24s) Loss: 0.3856 | Test Accuracy: 72.00% | Essa / Arabic ✓\n",
            "75000 75.00% (6m 50s) Loss: 0.1933 | Test Accuracy: 73.05% | Dubrowski / Russian ✓\n",
            "80000 80.00% (7m 15s) Loss: 0.0045 | Test Accuracy: 73.33% | Bezrukavnikov / Russian ✓\n",
            "85000 85.00% (7m 41s) Loss: 2.0761 | Test Accuracy: 73.70% | Makhlai / Arabic ✗ (Russian)\n",
            "90000 90.00% (8m 7s) Loss: 0.1186 | Test Accuracy: 70.14% | Rjavin / Russian ✓\n",
            "95000 95.00% (8m 33s) Loss: 0.3857 | Test Accuracy: 71.41% | Gaber / Arabic ✓\n",
            "100000 100.00% (9m 0s) Loss: 1.3959 | Test Accuracy: 72.75% | Fairlie / English ✓\n",
            "Training time with 512 hidden units: 540.13 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set parameters\n",
        "n_hidden = 256  # Double of 128\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Define function to train and evaluate the model\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "# Function to evaluate accuracy on test set\n",
        "def evaluate():\n",
        "    rnn.eval()\n",
        "    correct = 0\n",
        "    total = len(X_test)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total):\n",
        "            line = X_test[i]\n",
        "            category = y_test[i]\n",
        "            category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "            line_tensor = lineToTensor(line)\n",
        "\n",
        "            hidden = rnn.initHidden()\n",
        "            for j in range(line_tensor.size()[0]):\n",
        "                output, hidden = rnn(line_tensor[j], hidden)\n",
        "\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            if guess == category:\n",
        "                correct += 1\n",
        "    return correct / total\n",
        "\n",
        "# Time helper function\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# Start training with the defined hidden size\n",
        "start = time.time()\n",
        "\n",
        "# Initialize RNN with the new hidden size\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print progress\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        test_accuracy = evaluate()\n",
        "        print(f'{iter} {iter / n_iters * 100:.2f}% ({timeSince(start)}) Loss: {loss:.4f} | Test Accuracy: {test_accuracy * 100:.2f}% | {line} / {guess} {correct}')\n",
        "\n",
        "    # Plot losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0\n",
        "\n",
        "# Total training time\n",
        "total_time = time.time() - start\n",
        "print(f\"Training time with {n_hidden} hidden units: {total_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi9xfH-XM7CZ",
        "outputId": "d12c49bd-254a-4dcf-af21-2e1bcd53ed50"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000 5.00% (0m 14s) Loss: 0.0964 | Test Accuracy: 63.59% | Zaslavsky / Russian ✓\n",
            "10000 10.00% (0m 30s) Loss: 0.1652 | Test Accuracy: 65.11% | Zhovtyak / Russian ✓\n",
            "15000 15.00% (0m 44s) Loss: 0.0863 | Test Accuracy: 68.59% | Nezhlukto / Russian ✓\n",
            "20000 20.00% (0m 58s) Loss: 2.8927 | Test Accuracy: 71.16% | Gammer / Arabic ✗ (English)\n",
            "25000 25.00% (1m 12s) Loss: 0.0083 | Test Accuracy: 71.08% | Yakushkin / Russian ✓\n",
            "30000 30.00% (1m 27s) Loss: 0.0089 | Test Accuracy: 71.11% | Jafarov / Russian ✓\n",
            "35000 35.00% (1m 42s) Loss: 0.0287 | Test Accuracy: 72.18% | Abramtchuk / Russian ✓\n",
            "40000 40.00% (1m 56s) Loss: 0.9096 | Test Accuracy: 68.04% | VanPuteren / English ✗ (Russian)\n",
            "45000 45.00% (2m 15s) Loss: 0.3954 | Test Accuracy: 72.78% | Mihlin / Russian ✓\n",
            "50000 50.00% (2m 29s) Loss: 0.1025 | Test Accuracy: 73.25% | Mohosoev / Russian ✓\n",
            "55000 55.00% (2m 43s) Loss: 0.0002 | Test Accuracy: 71.01% | Jdankov / Russian ✓\n",
            "60000 60.00% (2m 57s) Loss: 1.1110 | Test Accuracy: 72.73% | Maynard / Arabic ✗ (English)\n",
            "65000 65.00% (3m 11s) Loss: 0.0122 | Test Accuracy: 71.48% | Vanyushin / Russian ✓\n",
            "70000 70.00% (3m 27s) Loss: 0.0001 | Test Accuracy: 74.02% | Zheltouhov / Russian ✓\n",
            "75000 75.00% (3m 42s) Loss: 2.4207 | Test Accuracy: 75.02% | Knef / Chinese ✗ (German)\n",
            "80000 80.00% (3m 56s) Loss: 0.0017 | Test Accuracy: 74.47% | Tzelovalnov / Russian ✓\n",
            "85000 85.00% (4m 10s) Loss: 3.8901 | Test Accuracy: 74.62% | Homa / Arabic ✗ (Russian)\n",
            "90000 90.00% (4m 25s) Loss: 0.9944 | Test Accuracy: 74.52% | Guan / Chinese ✓\n",
            "95000 95.00% (4m 38s) Loss: 0.1365 | Test Accuracy: 74.27% | Dubik / Russian ✓\n",
            "100000 100.00% (4m 52s) Loss: 0.0059 | Test Accuracy: 71.18% | Yoshikawa / Japanese ✓\n",
            "Training time with 256 hidden units: 292.67 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "n_hidden = 64  # Half of 128\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Define function to train and evaluate the model\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "# Function to evaluate accuracy on test set\n",
        "def evaluate():\n",
        "    rnn.eval()\n",
        "    correct = 0\n",
        "    total = len(X_test)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total):\n",
        "            line = X_test[i]\n",
        "            category = y_test[i]\n",
        "            category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "            line_tensor = lineToTensor(line)\n",
        "\n",
        "            hidden = rnn.initHidden()\n",
        "            for j in range(line_tensor.size()[0]):\n",
        "                output, hidden = rnn(line_tensor[j], hidden)\n",
        "\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            if guess == category:\n",
        "                correct += 1\n",
        "    return correct / total\n",
        "\n",
        "# Time helper function\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# Start training with the defined hidden size\n",
        "start = time.time()\n",
        "\n",
        "# Initialize RNN with the new hidden size\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print progress\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        test_accuracy = evaluate()\n",
        "        print(f'{iter} {iter / n_iters * 100:.2f}% ({timeSince(start)}) Loss: {loss:.4f} | Test Accuracy: {test_accuracy * 100:.2f}% | {line} / {guess} {correct}')\n",
        "\n",
        "    # Plot losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0\n",
        "\n",
        "# Total training time\n",
        "total_time = time.time() - start\n",
        "print(f\"Training time with {n_hidden} hidden units: {total_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pujJ63Ofq2Rw",
        "outputId": "7b89ca40-d00e-496b-dffc-c3224e8cdd21"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000 5.00% (0m 11s) Loss: 1.3876 | Test Accuracy: 56.19% | Elven / Russian ✗ (English)\n",
            "10000 10.00% (0m 22s) Loss: 0.0217 | Test Accuracy: 59.48% | Pechatkin / Russian ✓\n",
            "15000 15.00% (0m 34s) Loss: 0.6410 | Test Accuracy: 68.17% | Kumasaka / Japanese ✓\n",
            "20000 20.00% (0m 47s) Loss: 0.5448 | Test Accuracy: 67.07% | Jakush / Russian ✓\n",
            "25000 25.00% (1m 1s) Loss: 0.4399 | Test Accuracy: 70.56% | Alford / English ✓\n",
            "30000 30.00% (1m 14s) Loss: 1.3042 | Test Accuracy: 68.89% | Handal / English ✗ (Arabic)\n",
            "35000 35.00% (1m 26s) Loss: 0.4850 | Test Accuracy: 70.73% | Koury / Arabic ✓\n",
            "40000 40.00% (1m 38s) Loss: 0.5967 | Test Accuracy: 71.43% | Arian / Arabic ✓\n",
            "45000 45.00% (1m 50s) Loss: 0.0092 | Test Accuracy: 72.60% | Tzalykhin / Russian ✓\n",
            "50000 50.00% (2m 2s) Loss: 0.1429 | Test Accuracy: 73.45% | Hudik / Russian ✓\n",
            "55000 55.00% (2m 16s) Loss: 1.6039 | Test Accuracy: 74.40% | Ventura / Italian ✓\n",
            "60000 60.00% (2m 31s) Loss: 0.0912 | Test Accuracy: 73.08% | Kalinovich / Russian ✓\n",
            "65000 65.00% (2m 42s) Loss: 0.9093 | Test Accuracy: 72.00% | Elkington / Russian ✗ (English)\n",
            "70000 70.00% (2m 52s) Loss: 0.0680 | Test Accuracy: 74.00% | Joltovsky / Russian ✓\n",
            "75000 75.00% (3m 3s) Loss: 0.0056 | Test Accuracy: 74.97% | Agamirov / Russian ✓\n",
            "80000 80.00% (3m 15s) Loss: 0.0114 | Test Accuracy: 74.25% | Mikhnenko / Russian ✓\n",
            "85000 85.00% (3m 26s) Loss: 0.5624 | Test Accuracy: 74.45% | Boutros / Arabic ✓\n",
            "90000 90.00% (3m 38s) Loss: 0.0263 | Test Accuracy: 75.49% | Shalhoub / Arabic ✓\n",
            "95000 95.00% (3m 50s) Loss: 0.2202 | Test Accuracy: 76.59% | Noguchi / Japanese ✓\n",
            "100000 100.00% (4m 2s) Loss: 0.0098 | Test Accuracy: 76.41% | Mintskovsky / Russian ✓\n",
            "Training time with 64 hidden units: 242.42 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hidden layer size comparison is:\n",
        "\n",
        "- 64: reaches ~76 percent accuracy\n",
        "- 128: reaches ~77 percent accuracy\n",
        "- 256: reaches ~74 percent accuracy\n",
        "- 512: reaches ~72 percent accuracy\n",
        "\n",
        "From all the tests it seems tha 128 hidden layer size was the bets approach, all the other multiple for chunks calculation, result in a worse accuracy. This means that an optimal size must be around 128."
      ],
      "metadata": {
        "id": "wKFXxkl4tORs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d\\)**"
      ],
      "metadata": {
        "id": "iPlRZ4j2sBwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# LSTM Model\n",
        "class LSTM_Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTM_Model, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
        "\n",
        "        # Output layer\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        out, (hidden, cell) = self.lstm(input.view(1, 1, -1), hidden)\n",
        "        output = self.h2o(out.view(1, -1))\n",
        "        output = self.softmax(output)\n",
        "        return output, (hidden, cell)\n",
        "\n",
        "    def initHidden(self):\n",
        "        # Initialize hidden and cell state as zeros for LSTM\n",
        "        return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))\n",
        "\n",
        "\n",
        "# GRU Model\n",
        "class GRU_Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GRU_Model, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # GRU layer\n",
        "        self.gru = nn.GRU(input_size, hidden_size)\n",
        "\n",
        "        # Output layer\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        out, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
        "        output = self.h2o(out.view(1, -1))\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        # Initialize hidden state as zeros for GRU\n",
        "        return torch.zeros(1, 1, self.hidden_size)\n"
      ],
      "metadata": {
        "id": "9ONxMuZRsAqp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import string\n",
        "\n",
        "# Function to evaluate accuracy on test set\n",
        "def evaluate(rnn, X_test, y_test, all_categories):\n",
        "    rnn.eval()\n",
        "    correct = 0\n",
        "    total = len(X_test)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total):\n",
        "            line = X_test[i]\n",
        "            category = y_test[i]\n",
        "            category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "            line_tensor = lineToTensor(line)\n",
        "\n",
        "            hidden = rnn.initHidden()\n",
        "            for j in range(line_tensor.size()[0]):\n",
        "                output, hidden = rnn(line_tensor[j], hidden)\n",
        "\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            if guess == category:\n",
        "                correct += 1\n",
        "    return correct / total\n",
        "\n",
        "# Time helper function\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "# Set parameters\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Training function\n",
        "def train(rnn, category_tensor, line_tensor, criterion):\n",
        "    hidden = rnn.initHidden()\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "# Main training loop\n",
        "def train_and_evaluate_with_model(rnn, n_iters, print_every, plot_every, criterion, X_test, y_test, all_categories):\n",
        "    start = time.time()\n",
        "    current_loss = 0\n",
        "    all_losses = []\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        category, line, category_tensor, line_tensor = randomTrainingExample()  # Define this function\n",
        "        output, loss = train(rnn, category_tensor, line_tensor, criterion)\n",
        "        current_loss += loss\n",
        "\n",
        "        # Print progress\n",
        "        if iter % print_every == 0:\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "            test_accuracy = evaluate(rnn, X_test, y_test, all_categories)\n",
        "            print(f'{iter} {iter / n_iters * 100:.2f}% ({timeSince(start)}) Loss: {loss:.4f} | Test Accuracy: {test_accuracy * 100:.2f}% | {line} / {guess} {correct}')\n",
        "\n",
        "        # Plot losses\n",
        "        if iter % plot_every == 0:\n",
        "            all_losses.append(current_loss / plot_every)\n",
        "            current_loss = 0\n",
        "\n",
        "# Initialize models and evaluate\n",
        "def run_model_evaluation():\n",
        "    # Use CPU device\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(f\"Training on {device}\")\n",
        "\n",
        "    # Initialize the models (LSTM and GRU) and define the loss function\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    # LSTM\n",
        "    lstm_model = LSTM_Model(n_letters, 256, n_categories).to(device)\n",
        "    print(\"Training LSTM Model...\")\n",
        "    train_and_evaluate_with_model(lstm_model, n_iters, print_every, plot_every, criterion, X_test, y_test, all_categories)\n",
        "\n",
        "    # GRU\n",
        "    gru_model = GRU_Model(n_letters, 256, n_categories).to(device)\n",
        "    print(\"\\nTraining GRU Model...\")\n",
        "    train_and_evaluate_with_model(gru_model, n_iters, print_every, plot_every, criterion, X_test, y_test, all_categories)\n",
        "\n",
        "# Start model evaluation\n",
        "run_model_evaluation()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmYE8Pywx66n",
        "outputId": "b2603546-2336-4535-e6eb-f7238863f81e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Training LSTM Model...\n",
            "5000 5.00% (1m 12s) Loss: 0.7635 | Test Accuracy: 46.92% | Poretsky / Russian ✓\n",
            "10000 10.00% (2m 22s) Loss: 0.4476 | Test Accuracy: 50.59% | Isachenko / Russian ✓\n",
            "15000 15.00% (3m 35s) Loss: 2.8927 | Test Accuracy: 52.40% | Por / English ✗ (Russian)\n",
            "20000 20.00% (4m 46s) Loss: 4.7764 | Test Accuracy: 58.53% | Mckay / Russian ✗ (Scottish)\n",
            "25000 25.00% (5m 58s) Loss: 1.0788 | Test Accuracy: 59.58% | Nahas / Arabic ✓\n",
            "30000 30.00% (7m 11s) Loss: 3.5862 | Test Accuracy: 59.80% | Foss / Arabic ✗ (French)\n",
            "35000 35.00% (8m 25s) Loss: 3.9018 | Test Accuracy: 60.85% | Manos / Arabic ✗ (Greek)\n",
            "40000 40.00% (9m 36s) Loss: 4.0898 | Test Accuracy: 61.87% | Durante / English ✗ (Spanish)\n",
            "45000 45.00% (10m 50s) Loss: 0.7107 | Test Accuracy: 62.89% | Amari / Arabic ✓\n",
            "50000 50.00% (12m 0s) Loss: 0.0004 | Test Accuracy: 63.14% | Abubekerov / Russian ✓\n",
            "55000 55.00% (13m 12s) Loss: 2.8080 | Test Accuracy: 65.85% | Janca / English ✗ (Czech)\n",
            "60000 60.00% (14m 24s) Loss: 0.0265 | Test Accuracy: 67.80% | Varakin / Russian ✓\n",
            "65000 65.00% (15m 36s) Loss: 0.0129 | Test Accuracy: 64.66% | Schepelev / Russian ✓\n",
            "70000 70.00% (16m 48s) Loss: 3.4185 | Test Accuracy: 68.14% | Por / English ✗ (Russian)\n",
            "75000 75.00% (18m 0s) Loss: 0.0075 | Test Accuracy: 69.19% | Yakovkin / Russian ✓\n",
            "80000 80.00% (19m 13s) Loss: 0.1572 | Test Accuracy: 69.44% | Mimasuya / Japanese ✓\n",
            "85000 85.00% (20m 25s) Loss: 0.1750 | Test Accuracy: 69.94% | Anderton / English ✓\n",
            "90000 90.00% (21m 37s) Loss: 0.0198 | Test Accuracy: 69.29% | Pribylovsky / Russian ✓\n",
            "95000 95.00% (22m 52s) Loss: 0.5388 | Test Accuracy: 71.66% | Mustafa / Arabic ✓\n",
            "100000 100.00% (24m 4s) Loss: 0.0077 | Test Accuracy: 71.03% | Desyatov / Russian ✓\n",
            "\n",
            "Training GRU Model...\n",
            "5000 5.00% (0m 37s) Loss: 4.0684 | Test Accuracy: 49.07% | Close / English ✗ (Greek)\n",
            "10000 10.00% (1m 15s) Loss: 0.1027 | Test Accuracy: 55.32% | Pochuev / Russian ✓\n",
            "15000 15.00% (1m 54s) Loss: 0.9241 | Test Accuracy: 57.86% | Burt / English ✓\n",
            "20000 20.00% (2m 31s) Loss: 0.8448 | Test Accuracy: 61.32% | Simmons / English ✓\n",
            "25000 25.00% (3m 9s) Loss: 1.2646 | Test Accuracy: 63.44% | Tahan / Arabic ✓\n",
            "30000 30.00% (3m 46s) Loss: 3.3913 | Test Accuracy: 65.45% | Petit / English ✗ (French)\n",
            "35000 35.00% (4m 23s) Loss: 1.4445 | Test Accuracy: 67.42% | Onohara / Arabic ✗ (Japanese)\n",
            "40000 40.00% (5m 1s) Loss: 3.2339 | Test Accuracy: 68.52% | Katz / Arabic ✗ (German)\n",
            "45000 45.00% (5m 39s) Loss: 0.5930 | Test Accuracy: 67.47% | Ronchi / Italian ✓\n",
            "50000 50.00% (6m 19s) Loss: 0.1044 | Test Accuracy: 69.14% | Yuditsky / Russian ✓\n",
            "55000 55.00% (6m 56s) Loss: 0.0088 | Test Accuracy: 69.14% | Bahovkin / Russian ✓\n",
            "60000 60.00% (7m 33s) Loss: 1.2166 | Test Accuracy: 70.44% | Birich / English ✗ (Russian)\n",
            "65000 65.00% (8m 10s) Loss: 1.7114 | Test Accuracy: 69.64% | Derich / English ✗ (Russian)\n",
            "70000 70.00% (8m 49s) Loss: 0.0007 | Test Accuracy: 71.03% | Mukovozov / Russian ✓\n",
            "75000 75.00% (9m 26s) Loss: 0.0038 | Test Accuracy: 71.93% | Fisichev / Russian ✓\n",
            "80000 80.00% (10m 3s) Loss: 0.2023 | Test Accuracy: 68.69% | Pelih / Russian ✓\n",
            "85000 85.00% (10m 41s) Loss: 0.6399 | Test Accuracy: 70.98% | Sewell / English ✓\n",
            "90000 90.00% (11m 20s) Loss: 0.0181 | Test Accuracy: 72.83% | Momotov / Russian ✓\n",
            "95000 95.00% (11m 57s) Loss: 0.0135 | Test Accuracy: 72.75% | Mojaev / Russian ✓\n",
            "100000 100.00% (12m 37s) Loss: 0.5798 | Test Accuracy: 71.83% | Rembeza / Russian ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The use of a LSTM or GRU Model show a constant increase of model performance in comparison with evaluation of RNN. But the RNN model still perfoms better than both of these alternatives, this might relay on HyperparameterTuning, or on the case of the data base not being large enough.\n"
      ],
      "metadata": {
        "id": "FLpAZXRe0I_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e\\)**"
      ],
      "metadata": {
        "id": "5v8hNEj6sEv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Force everything to run on CPU\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Training function for a specific optimizer\n",
        "def train_with_optimizer(optimizer, category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden().to(device)  # Ensure hidden is on CPU\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()  # Update model parameters\n",
        "    return output, loss.item()\n",
        "\n",
        "# Function to train and evaluate the model using different optimizers\n",
        "def run_training_and_evaluation():\n",
        "    optimizer_classes = {\n",
        "        'SGD': torch.optim.SGD,\n",
        "        'Adam': torch.optim.Adam,\n",
        "        'RMSprop': torch.optim.RMSprop\n",
        "    }\n",
        "\n",
        "    for optimizer_name, optimizer_class in optimizer_classes.items():\n",
        "        print(f\"\\nTraining with {optimizer_name} optimizer...\")\n",
        "\n",
        "        # Initialize the model and optimizer\n",
        "        rnn = RNN(n_letters, 128, n_categories).to(device)  # Hidden layer size of 128, model moved to CPU\n",
        "        optimizer = optimizer_class(rnn.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Start training\n",
        "        start = time.time()\n",
        "        current_loss = 0\n",
        "        all_losses = []\n",
        "\n",
        "        for iter in range(1, n_iters + 1):\n",
        "            category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "            category_tensor = category_tensor.to(device)  # Move to CPU\n",
        "            line_tensor = line_tensor.to(device)  # Move to CPU\n",
        "            output, loss = train_with_optimizer(optimizer, category_tensor, line_tensor)\n",
        "            current_loss += loss\n",
        "\n",
        "            # Print progress\n",
        "            if iter % print_every == 0:\n",
        "                guess, guess_i = categoryFromOutput(output)\n",
        "                correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "                test_accuracy = evaluate(rnn)  # Ensure evaluate uses the correct rnn\n",
        "                print(f'{iter} {iter / n_iters * 100:.2f}% ({timeSince(start)}) Loss: {loss:.4f} | '\n",
        "                      f'Test Accuracy: {test_accuracy * 100:.2f}% | {line} / {guess} {correct}')\n",
        "\n",
        "            # Plot losses\n",
        "            if iter % plot_every == 0:\n",
        "                all_losses.append(current_loss / plot_every)\n",
        "                current_loss = 0\n",
        "\n",
        "        total_time = time.time() - start\n",
        "        print(f\"Training time with {optimizer_name}: {total_time:.2f} seconds\\n\")\n",
        "\n",
        "# Ensure evaluate() works with the provided rnn\n",
        "def evaluate(rnn):\n",
        "    rnn.eval()\n",
        "    correct = 0\n",
        "    total = len(X_test)\n",
        "    with torch.no_grad():\n",
        "        for i in range(total):\n",
        "            line = X_test[i]\n",
        "            category = y_test[i]\n",
        "            category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long).to(device)\n",
        "            line_tensor = lineToTensor(line).to(device)\n",
        "\n",
        "            hidden = rnn.initHidden().to(device)\n",
        "            for j in range(line_tensor.size()[0]):\n",
        "                output, hidden = rnn(line_tensor[j], hidden)\n",
        "\n",
        "            guess, guess_i = categoryFromOutput(output)\n",
        "            if guess == category:\n",
        "                correct += 1\n",
        "    return correct / total\n",
        "\n",
        "# Call the function to run training and evaluation for all optimizers\n",
        "run_training_and_evaluation()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvEuwRpC3ezh",
        "outputId": "1ace5e65-d628-4f0a-88e0-05e114a1fb4e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Training with SGD optimizer...\n",
            "5000 5.00% (0m 25s) Loss: 0.7136 | Test Accuracy: 8.00% | Kempster / English ✓\n",
            "10000 10.00% (0m 49s) Loss: 0.8980 | Test Accuracy: 8.00% | Shinko / Russian ✗ (Japanese)\n",
            "15000 15.00% (1m 14s) Loss: 0.0083 | Test Accuracy: 8.00% | Serejnikov / Russian ✓\n",
            "20000 20.00% (1m 39s) Loss: 0.0090 | Test Accuracy: 8.00% | Agaloff / Russian ✓\n",
            "25000 25.00% (2m 5s) Loss: 1.9954 | Test Accuracy: 8.00% | Li / Italian ✗ (Russian)\n",
            "30000 30.00% (2m 30s) Loss: 0.4354 | Test Accuracy: 8.00% | Watanabe / Japanese ✓\n",
            "35000 35.00% (2m 55s) Loss: 0.0027 | Test Accuracy: 8.00% | Marhanov / Russian ✓\n",
            "40000 40.00% (3m 19s) Loss: 0.0706 | Test Accuracy: 8.00% | Hamraev / Russian ✓\n",
            "45000 45.00% (3m 43s) Loss: 1.6406 | Test Accuracy: 8.00% | Lagomarsino / Japanese ✗ (Italian)\n",
            "50000 50.00% (4m 8s) Loss: 0.6394 | Test Accuracy: 8.00% | Astbury / English ✓\n",
            "55000 55.00% (4m 32s) Loss: 0.2316 | Test Accuracy: 8.00% | Ganim / Arabic ✓\n",
            "60000 60.00% (4m 57s) Loss: 2.4075 | Test Accuracy: 8.00% | Brivio / Russian ✗ (Italian)\n",
            "65000 65.00% (5m 23s) Loss: 1.9933 | Test Accuracy: 8.00% | Altimari / Japanese ✗ (Italian)\n",
            "70000 70.00% (5m 50s) Loss: 0.0736 | Test Accuracy: 8.00% | Said / Arabic ✓\n",
            "75000 75.00% (6m 15s) Loss: 1.2293 | Test Accuracy: 8.00% | Fairchild / Russian ✗ (English)\n",
            "80000 80.00% (6m 41s) Loss: 0.4763 | Test Accuracy: 8.00% | Hotta / Japanese ✓\n",
            "85000 85.00% (7m 7s) Loss: 0.9165 | Test Accuracy: 8.00% | Mclean / English ✓\n",
            "90000 90.00% (7m 33s) Loss: 0.0445 | Test Accuracy: 8.00% | Zelensky / Russian ✓\n",
            "95000 95.00% (8m 0s) Loss: 3.9912 | Test Accuracy: 8.00% | Cuidightheach / Russian ✗ (Irish)\n",
            "100000 100.00% (8m 27s) Loss: 0.0004 | Test Accuracy: 8.00% | Paholkov / Russian ✓\n",
            "Training time with SGD: 507.55 seconds\n",
            "\n",
            "\n",
            "Training with Adam optimizer...\n",
            "5000 5.00% (0m 27s) Loss: 0.0044 | Test Accuracy: 2.47% | Nasretdinov / Russian ✓\n",
            "10000 10.00% (0m 53s) Loss: 0.3230 | Test Accuracy: 2.47% | Opova / Czech ✓\n",
            "15000 15.00% (1m 23s) Loss: 2.7338 | Test Accuracy: 2.47% | Brezovjak / Russian ✗ (Czech)\n",
            "20000 20.00% (1m 50s) Loss: 0.0019 | Test Accuracy: 2.47% | Baimakov / Russian ✓\n",
            "25000 25.00% (2m 17s) Loss: 0.7715 | Test Accuracy: 2.47% | Ghanem / Arabic ✓\n",
            "30000 30.00% (2m 43s) Loss: 0.0024 | Test Accuracy: 2.47% | Mlachnev / Russian ✓\n",
            "35000 35.00% (3m 11s) Loss: 0.0381 | Test Accuracy: 2.47% | Yakushkin / Russian ✓\n",
            "40000 40.00% (3m 36s) Loss: 1.2622 | Test Accuracy: 2.47% | Chieu / Chinese ✓\n",
            "45000 45.00% (4m 1s) Loss: 0.4072 | Test Accuracy: 2.47% | Chance / English ✓\n",
            "50000 50.00% (4m 26s) Loss: 0.6524 | Test Accuracy: 2.47% | Best / German ✓\n",
            "55000 55.00% (4m 50s) Loss: 0.0013 | Test Accuracy: 2.47% | Bajanov / Russian ✓\n",
            "60000 60.00% (5m 15s) Loss: 0.2155 | Test Accuracy: 2.47% | Cham / Arabic ✓\n",
            "65000 65.00% (5m 39s) Loss: 1.0346 | Test Accuracy: 2.47% | Animitsa / Japanese ✗ (Russian)\n",
            "70000 70.00% (6m 4s) Loss: 0.0448 | Test Accuracy: 2.47% | Zhurihin / Russian ✓\n",
            "75000 75.00% (6m 29s) Loss: 0.3877 | Test Accuracy: 2.47% | Badalbeili / Russian ✓\n",
            "80000 80.00% (6m 53s) Loss: 4.5467 | Test Accuracy: 2.47% | Esteves / English ✗ (Portuguese)\n",
            "85000 85.00% (7m 18s) Loss: 0.0026 | Test Accuracy: 2.47% | Rochegov / Russian ✓\n",
            "90000 90.00% (7m 42s) Loss: 0.0070 | Test Accuracy: 2.47% | Hasiev / Russian ✓\n",
            "95000 95.00% (8m 7s) Loss: 0.9939 | Test Accuracy: 2.47% | Malinowski / Polish ✓\n",
            "100000 100.00% (8m 32s) Loss: 0.1991 | Test Accuracy: 2.47% | Farrier / English ✓\n",
            "Training time with Adam: 512.33 seconds\n",
            "\n",
            "\n",
            "Training with RMSprop optimizer...\n",
            "5000 5.00% (0m 25s) Loss: 0.9843 | Test Accuracy: 0.67% | Ealham / English ✓\n",
            "10000 10.00% (0m 51s) Loss: 2.5782 | Test Accuracy: 0.67% | Wetterman / English ✗ (German)\n",
            "15000 15.00% (1m 17s) Loss: 0.1560 | Test Accuracy: 0.67% | Almasi / Arabic ✓\n",
            "20000 20.00% (1m 43s) Loss: 0.3143 | Test Accuracy: 0.67% | Arian / Arabic ✓\n",
            "25000 25.00% (2m 9s) Loss: 0.0809 | Test Accuracy: 0.67% | Bekhtin / Russian ✓\n",
            "30000 30.00% (2m 34s) Loss: 1.0611 | Test Accuracy: 0.67% | Zha / Chinese ✓\n",
            "35000 35.00% (3m 1s) Loss: 0.2337 | Test Accuracy: 0.67% | To The First Page / Russian ✓\n",
            "40000 40.00% (3m 27s) Loss: 0.7393 | Test Accuracy: 0.67% | Knowles / English ✓\n",
            "45000 45.00% (3m 53s) Loss: 4.6621 | Test Accuracy: 0.67% | Bischoffs / Russian ✗ (German)\n",
            "50000 50.00% (4m 19s) Loss: 0.0570 | Test Accuracy: 0.67% | Shahnarovich / Russian ✓\n",
            "55000 55.00% (4m 44s) Loss: 0.0033 | Test Accuracy: 0.67% | Averkov / Russian ✓\n",
            "60000 60.00% (5m 10s) Loss: 0.7429 | Test Accuracy: 0.67% | Fuchs / German ✓\n",
            "65000 65.00% (5m 35s) Loss: 0.0521 | Test Accuracy: 0.67% | Hloponin / Russian ✓\n",
            "70000 70.00% (6m 1s) Loss: 2.5845 | Test Accuracy: 0.67% | Mateu / Japanese ✗ (Spanish)\n",
            "75000 75.00% (6m 27s) Loss: 0.0021 | Test Accuracy: 0.67% | Bazarov / Russian ✓\n",
            "80000 80.00% (6m 53s) Loss: 0.7618 | Test Accuracy: 0.67% | Ciurlionis / Russian ✓\n",
            "85000 85.00% (7m 19s) Loss: 2.6177 | Test Accuracy: 0.67% | Bass / Arabic ✗ (Russian)\n",
            "90000 90.00% (7m 45s) Loss: 0.0012 | Test Accuracy: 0.67% | Bahtinov / Russian ✓\n",
            "95000 95.00% (8m 11s) Loss: 2.6531 | Test Accuracy: 0.67% | See / Chinese ✗ (Dutch)\n",
            "100000 100.00% (8m 39s) Loss: 1.6612 | Test Accuracy: 0.67% | Ott / English ✗ (Russian)\n",
            "Training time with RMSprop: 519.57 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Model should have more confidence on the classification of the name, the longer the name is, as the model would have more data to process through the hidden layers, which results in more precise predictions.\n",
        "\n",
        "The network is generally more confident in correct classifications, as the probability for the correct class is higher, while in incorrect classifications, the confidence (probability) is usually lower.\n",
        "\n",
        "All the current optimizers are possible alternatives but there seems to be a problem at the moment of updating the model as the accuracy never changed during the whole evaluation, but must lay down on the code.\n",
        "\n",
        "According to Internet forums, adam should be the best optimizer compared to the other ones, while SDG is the most basic and the default one.\n",
        "\n"
      ],
      "metadata": {
        "id": "0G_VdNKiDxAu"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}